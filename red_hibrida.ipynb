{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6eebc8",
   "metadata": {},
   "source": [
    "# Redes neuronales hibridas  para clasificación multiple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1f1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the relevant packages.\n",
    "#%pip install --upgrade pip\n",
    "#%pip install torch torchvision torchaudio\n",
    "#%pip install cudaq -> ya viene instalado en el braket de AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50673393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.12 (main, Oct 10 2025, 00:00:00) [GCC 15.2.1 20250808 (Red Hat 15.2.1-1)]\n",
      "PyTorch version: 2.9.0+cpu\n",
      "NumPy version: 2.2.6\n",
      "Matplotlib version: 3.10.7\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Check installed clasico\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "\n",
    "import torch, torchvision, torchaudio\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"vision:\", torchvision.__version__)\n",
    "print(\"audio:\", torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cudaq\n",
    "print(f\"CUDAQ version: {cudaq.__version__}\")\n",
    "print(f\"Running on target: {cudaq.get_target().name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cudaq\n",
    "\n",
    "print(f\"Running on target {cudaq.get_target().name}\")\n",
    "qubit_count = int(sys.argv[1]) if 1 < len(sys.argv) else 2\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel():\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "    h(qubits[0])\n",
    "    for i in range(1, qubit_count):\n",
    "        x.ctrl(qubits[0], qubits[i])\n",
    "    mz(qubits)\n",
    "\n",
    "\n",
    "result = cudaq.sample(kernel)\n",
    "print(result)  # Example: { 11:500 00:500 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918cbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar las librerías necesarias\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Para asegurar que los resultados sean reproducibles\n",
    "torch.manual_seed(42)\n",
    "\n",
    "cudaq.set_random_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582043a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el dispositivo\n",
    "# Set CUDAQ and PyTorch to run on either CPU or GPU.\n",
    "\n",
    "device = torch.device('cpu')\n",
    "cudaq.set_target(\"qpp-cpu\")\n",
    "\n",
    "#cudaq.set_target(\"nvidia\")\n",
    "#device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13cbb16",
   "metadata": {},
   "source": [
    "## Descripción del Conjunto de Datos MNIST\n",
    "\n",
    "- *¿Qué es?:* MNIST (Modified National Institute of Standards and Technology database) es una gran base de datos de dígitos escritos a mano, del 0 al 9.\n",
    "- *Contenido:* Contiene 70,000 imágenes en escala de grises.\n",
    "- *Conjunto de entrenamiento:* 60,000 imágenes.\n",
    "- *Conjunto de prueba:* 10,000 imágenes.\n",
    "- *Formato de imagen:* Cada imagen tiene un tamaño de 28x28 píxeles.\n",
    "- *Uso común:* Es considerado el \"Hola, Mundo\" de la visión por computadora y el aprendizaje profundo. Se utiliza para entrenar y probar algoritmos de clasificación de imágenes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeaf4a4",
   "metadata": {},
   "source": [
    "Paso 2: Cargar, Transformar y Previsualizar los Datos\n",
    "torchvision nos facilita la descarga y preparación de datasets.\n",
    "\n",
    "Transformaciones: Convertimos las imágenes a tensores de PyTorch y las normalizamos. La normalización (ajustar los valores de los píxeles para que tengan una media de 0.5 y una desviación estándar de 0.5) ayuda a que el modelo entrene más rápido y de forma más estable.\n",
    "Descarga: Descargamos los conjuntos de entrenamiento y prueba. FashionMNIST ya viene separado en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definir las transformaciones para las imágenes\n",
    "# - transforms.ToTensor() convierte la imagen (PIL) a un Tensor de PyTorch.\n",
    "# - transforms.Normalize() ajusta los valores del tensor para que tengan una media y desviación estándar específicas.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Media y Desviación Estándar para un solo canal (escala de grises)\n",
    "])\n",
    "\n",
    "# 2. Descargar los datasets de entrenamiento y prueba\n",
    "train_full_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Tamaño total del dataset de entrenamiento: {len(train_full_dataset)}\")\n",
    "print(f\"Tamaño del dataset de prueba: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los tamaños para la división train/validation\n",
    "train_size = int(0.8 * len(train_full_dataset)) # 80% para entrenamiento\n",
    "val_size = len(train_full_dataset) - train_size # 20% para validación\n",
    "\n",
    "# Dividimos el dataset de entrenamiento\n",
    "train_dataset, val_dataset = random_split(train_full_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Tamaño del subconjunto de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"Tamaño del subconjunto de validación: {len(val_dataset)}\")\n",
    "\n",
    "# Crear los DataLoaders\n",
    "# Los DataLoaders nos permiten iterar sobre los datos en lotes (batches)\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clases de MNIST (dígitos del 0 al 9)\n",
    "classes = tuple(str(i) for i in range(10))\n",
    "\n",
    "# Función para mostrar imágenes (sin cambios)\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Des-normalizar\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Obtener un lote de imágenes de entrenamiento\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Mostrar las primeras 8 imágenes y sus etiquetas\n",
    "print(\"--- Previsualización de Datos (MNIST) ---\")\n",
    "imshow(torchvision.utils.make_grid(images[:8]))\n",
    "print('Etiquetas: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # Capa 1: Entrada (784 neuronas) -> Oculta 1 (512 neuronas)\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            # Capa 2: Oculta 1 (512) -> Oculta 2 (256 neuronas)\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            # Capa 3: Oculta 2 (256) -> Oculta 3 (128 neuronas)\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            # Capa 4 (Salida): Oculta 3 (128) -> Salida (10 neuronas)\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Instanciamos el modelo y lo movemos al dispositivo (GPU/CPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = NeuralNetwork().to(device)\n",
    "print(\"\\n--- Arquitectura del Modelo ---\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a871d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Pérdida (loss): {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            val_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Resultado: \\n Precisión (Accuracy): {(100*correct):>0.1f}%, Pérdida promedio: {val_loss:>8f} \\n\")\n",
    "\n",
    "# Bucle principal de entrenamiento\n",
    "epochs = 10\n",
    "print(\"\\n--- Iniciando Entrenamiento con MNIST ---\")\n",
    "for t in range(epochs):\n",
    "    print(f\"Época {t+1}\\n-------------------------------\")\n",
    "    print(\"Entrenando...\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    print(\"Validando...\")\n",
    "    validation_loop(val_loader, model, loss_fn)\n",
    "print(\"¡Entrenamiento finalizado!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609016cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Evaluando con el conjunto de Prueba (Test) ---\")\n",
    "validation_loop(test_loader, model, loss_fn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
