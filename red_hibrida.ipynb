{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6eebc8",
   "metadata": {},
   "source": [
    "# Redes neuronales hibridas  para clasificación multiple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1f1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9a63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the relevant packages.\n",
    "#%pip install --upgrade pip\n",
    "#%pip install torch torchvision torchaudio\n",
    "#%pip install cudaq -> ya viene instalado en el braket de AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50673393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:29:10) [GCC 14.3.0]\n",
      "NumPy version: 1.26.4\n",
      "Matplotlib version: 3.10.7\n",
      "torch: 2.9.1+cu128\n",
      "vision: 0.24.1+cu128\n",
      "audio: 2.9.1+cu128\n"
     ]
    }
   ],
   "source": [
    "# Check installed clasico\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "\n",
    "import torch, torchvision, torchaudio\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"vision:\", torchvision.__version__)\n",
    "print(\"audio:\", torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5318ca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAQ version: CUDA-Q Version 0.12.0 (https://github.com/NVIDIA/cuda-quantum 6adf92bcda4df7465e4fe82f1c8f782ae69d8bd2)\n",
      "Running on target: qpp-cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cudaq\n",
    "print(f\"CUDAQ version: {cudaq.__version__}\")\n",
    "print(f\"Running on target: {cudaq.get_target().name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e02ebb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on target qpp-cpu\n",
      "{ 00:490 11:510 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cudaq\n",
    "\n",
    "print(f\"Running on target {cudaq.get_target().name}\")\n",
    "qubit_count = 2\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel():\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "    h(qubits[0])\n",
    "    for i in range(1, qubit_count):\n",
    "        x.ctrl(qubits[0], qubits[i])\n",
    "    mz(qubits)\n",
    "\n",
    "\n",
    "result = cudaq.sample(kernel)\n",
    "print(result)  # Example: { 11:500 00:500 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918cbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar las librerías necesarias\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Para asegurar que los resultados sean reproducibles\n",
    "torch.manual_seed(42)\n",
    "\n",
    "cudaq.set_random_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582043a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el dispositivo\n",
    "# Set CUDAQ and PyTorch to run on either CPU or GPU.\n",
    "\n",
    "device = torch.device('cpu')\n",
    "cudaq.set_target(\"qpp-cpu\")\n",
    "\n",
    "#cudaq.set_target(\"nvidia\")\n",
    "#device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13cbb16",
   "metadata": {},
   "source": [
    "## Descripción del Conjunto de Datos MNIST\n",
    "\n",
    "- *¿Qué es?:* MNIST (Modified National Institute of Standards and Technology database) es una gran base de datos de dígitos escritos a mano, del 0 al 9.\n",
    "- *Contenido:* Contiene 70,000 imágenes en escala de grises.\n",
    "- *Conjunto de entrenamiento:* 60,000 imágenes.\n",
    "- *Conjunto de prueba:* 10,000 imágenes.\n",
    "- *Formato de imagen:* Cada imagen tiene un tamaño de 28x28 píxeles.\n",
    "- *Uso común:* Es considerado el \"Hola, Mundo\" de la visión por computadora y el aprendizaje profundo. Se utiliza para entrenar y probar algoritmos de clasificación de imágenes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeaf4a4",
   "metadata": {},
   "source": [
    "Paso 2: Cargar, Transformar y Previsualizar los Datos\n",
    "torchvision nos facilita la descarga y preparación de datasets.\n",
    "\n",
    "Transformaciones: Convertimos las imágenes a tensores de PyTorch y las normalizamos. La normalización (ajustar los valores de los píxeles para que tengan una media de 0.5 y una desviación estándar de 0.5) ayuda a que el modelo entrene más rápido y de forma más estable.\n",
    "Descarga: Descargamos los conjuntos de entrenamiento y prueba. FashionMNIST ya viene separado en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e44f6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño total del dataset de entrenamiento: 60000\n",
      "Tamaño del dataset de prueba: 10000\n"
     ]
    }
   ],
   "source": [
    "# 1. Definir las transformaciones para las imágenes\n",
    "# - transforms.ToTensor() convierte la imagen (PIL) a un Tensor de PyTorch.\n",
    "# - transforms.Normalize() ajusta los valores del tensor para que tengan una media y desviación estándar específicas.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Media y Desviación Estándar para un solo canal (escala de grises)\n",
    "])\n",
    "\n",
    "# 2. Descargar los datasets de entrenamiento y prueba\n",
    "train_full_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Tamaño total del dataset de entrenamiento: {len(train_full_dataset)}\")\n",
    "print(f\"Tamaño del dataset de prueba: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "292e67e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del subconjunto de entrenamiento: 800\n",
      "Tamaño del subconjunto de validación: 200\n"
     ]
    }
   ],
   "source": [
    "# --- MODIFICACIÓN: Usar solo 1000 muestras para una prueba rápida ---\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# 1. Creamos un subconjunto con las primeras 1000 imágenes del dataset de entrenamiento completo\n",
    "n_samples_prueba = 1000\n",
    "train_subset_for_testing = Subset(train_full_dataset, range(n_samples_prueba))\n",
    "\n",
    "# 2. Ahora, basamos la división 80/20 en este subconjunto de 1000 muestras\n",
    "train_size = int(0.8 * len(train_subset_for_testing)) # 80% de 1000 = 800\n",
    "val_size = len(train_subset_for_testing) - train_size # 20% de 1000 = 200\n",
    "\n",
    "# Dividimos el dataset de entrenamiento\n",
    "train_dataset, val_dataset = random_split(train_subset_for_testing, [train_size, val_size])\n",
    "\n",
    "print(f\"Tamaño del subconjunto de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"Tamaño del subconjunto de validación: {len(val_dataset)}\")\n",
    "\n",
    "# Crear los DataLoaders\n",
    "# Los DataLoaders nos permiten iterar sobre los datos en lotes (batches)\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2345870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Previsualización de Datos (MNIST) ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas:  5     2     9     9     8     3     3     7    \n"
     ]
    }
   ],
   "source": [
    "# Clases de MNIST (dígitos del 0 al 9)\n",
    "classes = tuple(str(i) for i in range(10))\n",
    "\n",
    "# Función para mostrar imágenes (sin cambios)\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Des-normalizar\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Obtener un lote de imágenes de entrenamiento\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Mostrar las primeras 8 imágenes y sus etiquetas\n",
    "print(\"--- Previsualización de Datos (MNIST) ---\")\n",
    "imshow(torchvision.utils.make_grid(images[:8]))\n",
    "print('Etiquetas: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c14a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Arquitectura del Modelo ---\n",
      "CNN(\n",
      "  (conv_stack): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc_stack): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=1600, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Bloque convolucional para extracción de características\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            # Entrada: 1x28x28 -> Salida: 32x26x26\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            # Entrada: 32x26x26 -> Salida: 32x13x13\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # Entrada: 32x13x13 -> Salida: 64x11x11\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            # Entrada: 64x11x11 -> Salida: 64x5x5\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        # Aplanador y clasificador\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_stack = nn.Sequential(\n",
    "            # Previene el sobreajuste\n",
    "            nn.Dropout(0.5),\n",
    "            # Mapea las características a las 10 clases de salida\n",
    "            # La entrada es 64*5*5 = 1600\n",
    "            nn.Linear(64 * 5 * 5, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pasa la imagen por las capas convolucionales\n",
    "        x = self.conv_stack(x)\n",
    "        # Aplana el resultado para la capa densa\n",
    "        x = self.flatten(x)\n",
    "        # Pasa por el clasificador final\n",
    "        logits = self.fc_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Instanciamos el modelo y lo movemos al dispositivo (GPU/CPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CNN().to(device)\n",
    "print(\"\\n--- Arquitectura del Modelo ---\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a885b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51a871d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Entrenamiento con MNIST ---\n",
      "Época 1\n",
      "-------------------------------\n",
      "Entrenando...\n",
      "Pérdida (loss): 2.326925  [   64/  800]\n",
      "Validando...\n",
      "Resultado: \n",
      " Precisión (Accuracy): 73.5%, Pérdida promedio: 1.637920 \n",
      "\n",
      "Época 2\n",
      "-------------------------------\n",
      "Entrenando...\n",
      "Pérdida (loss): 1.636946  [   64/  800]\n",
      "Validando...\n",
      "Resultado: \n",
      " Precisión (Accuracy): 83.0%, Pérdida promedio: 0.860735 \n",
      "\n",
      "Época 3\n",
      "-------------------------------\n",
      "Entrenando...\n",
      "Pérdida (loss): 0.589803  [   64/  800]\n",
      "Validando...\n",
      "Resultado: \n",
      " Precisión (Accuracy): 85.5%, Pérdida promedio: 0.667567 \n",
      "\n",
      "Época 4\n",
      "-------------------------------\n",
      "Entrenando...\n",
      "Pérdida (loss): 0.433944  [   64/  800]\n",
      "Validando...\n",
      "Resultado: \n",
      " Precisión (Accuracy): 88.0%, Pérdida promedio: 0.574240 \n",
      "\n",
      "Época 5\n",
      "-------------------------------\n",
      "Entrenando...\n",
      "Pérdida (loss): 0.403675  [   64/  800]\n",
      "Validando...\n",
      "Resultado: \n",
      " Precisión (Accuracy): 89.0%, Pérdida promedio: 0.524867 \n",
      "\n",
      "Época 6\n",
      "-------------------------------\n",
      "Entrenando...\n",
      "Pérdida (loss): 0.189023  [   64/  800]\n",
      "Validando...\n",
      "Resultado: \n",
      " Precisión (Accuracy): 91.0%, Pérdida promedio: 0.490625 \n",
      "\n",
      "Época 7\n",
      "-------------------------------\n",
      "Entrenando...\n",
      "Pérdida (loss): 0.413564  [   64/  800]\n",
      "Validando...\n",
      "Resultado: \n",
      " Precisión (Accuracy): 90.5%, Pérdida promedio: 0.485467 \n",
      "\n",
      "Época 8\n",
      "-------------------------------\n",
      "Entrenando...\n",
      "Pérdida (loss): 0.167088  [   64/  800]\n",
      "Validando...\n",
      "Resultado: \n",
      " Precisión (Accuracy): 91.0%, Pérdida promedio: 0.463443 \n",
      "\n",
      "Época 9\n",
      "-------------------------------\n",
      "Entrenando...\n",
      "Pérdida (loss): 0.216318  [   64/  800]\n",
      "Validando...\n",
      "Resultado: \n",
      " Precisión (Accuracy): 92.5%, Pérdida promedio: 0.441000 \n",
      "\n",
      "Época 10\n",
      "-------------------------------\n",
      "Entrenando...\n",
      "Pérdida (loss): 0.168450  [   64/  800]\n",
      "Validando...\n",
      "Resultado: \n",
      " Precisión (Accuracy): 91.0%, Pérdida promedio: 0.449003 \n",
      "\n",
      "¡Entrenamiento finalizado!\n"
     ]
    }
   ],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Pérdida (loss): {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            val_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Resultado: \\n Precisión (Accuracy): {(100*correct):>0.1f}%, Pérdida promedio: {val_loss:>8f} \\n\")\n",
    "\n",
    "# Bucle principal de entrenamiento\n",
    "epochs = 10\n",
    "print(\"\\n--- Iniciando Entrenamiento con MNIST ---\")\n",
    "for t in range(epochs):\n",
    "    print(f\"Época {t+1}\\n-------------------------------\")\n",
    "    print(\"Entrenando...\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    print(\"Validando...\")\n",
    "    validation_loop(val_loader, model, loss_fn)\n",
    "print(\"¡Entrenamiento finalizado!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "609016cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluando con el conjunto de Prueba (Test) ---\n",
      "Resultado: \n",
      " Precisión (Accuracy): 92.4%, Pérdida promedio: 0.245266 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluando con el conjunto de Prueba (Test) ---\")\n",
    "validation_loop(test_loader, model, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bfb2cf2-d5f8-4fd1-a150-a0715a1a9fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Modelo guardado exitosamente en cnn_mnist_weights.pth!\n"
     ]
    }
   ],
   "source": [
    "# --- Guardar los pesos del modelo entrenado ---\n",
    "\n",
    "def save_model(model, name):\n",
    "    # Define el nombre del archivo donde se guardarán los pesos.\n",
    "    RUTA_MODELO = f\"{name}.pth\"\n",
    "    # Usamos model.state_dict() para obtener solo los parámetros aprendibles.\n",
    "    torch.save(model.state_dict(), RUTA_MODELO)\n",
    "    print(f\"¡Modelo guardado exitosamente en {RUTA_MODELO}!\")\n",
    "\n",
    "save_model(model, \"cnn_mnist_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd9cb5-5e94-40f2-9ede-5a9ce6e0bc0c",
   "metadata": {},
   "source": [
    "## Implementación del Modelo Híbrido Cuántico-Clásico\n",
    "\n",
    "Ahora, construiremos y entrenaremos el modelo híbrido. Este modelo combinará capas convolucionales clásicas para la extracción de características con un circuito cuántico parametrizado para el procesamiento de la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-model-def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65c47104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Arquitectura del Modelo Híbrido ---\n",
      "HybridCNN(\n",
      "  (conv_stack): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (pre_quantum_fc): Linear(in_features=1600, out_features=4, bias=True)\n",
      "  (quantum_layer): QuantumLayer()\n",
      "  (post_quantum_fc): Linear(in_features=4, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# DEFINIR EL KERNEL DE FORMA GLOBAL (FUERA DE LA CLASE)\n",
    "def create_quantum_kernel(n_qubits: int):\n",
    "    \"\"\"Factory para crear kernels cuánticos\"\"\"\n",
    "    @cudaq.kernel\n",
    "    def quantum_kernel(features: list[float]) -> None:  # ✅ Anotación correcta\n",
    "        \"\"\"\n",
    "        Kernel cuántico parametrizado\n",
    "        \n",
    "        Args:\n",
    "            features: Lista de características (ángulos)\n",
    "        \"\"\"\n",
    "        qubits = cudaq.qvector(n_qubits)\n",
    "        \n",
    "        # Codificación de características con rotaciones RY\n",
    "        for i in range(len(features)):\n",
    "            ry(features[i] * 3.14159, qubits[i])\n",
    "        \n",
    "        # Entrelazamiento con compuertas CNOT\n",
    "        for i in range(n_qubits - 1):\n",
    "            cx(qubits[i], qubits[i + 1])\n",
    "    \n",
    "    return quantum_kernel\n",
    "\n",
    "\n",
    "class QuantumFunction(torch.autograd.Function):\n",
    "    \"\"\"Función personalizada de autograd para ejecutar circuitos cuánticos\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x, kernel, hamiltonian, n_features, n_outputs_quantum):\n",
    "        \"\"\"\n",
    "        Ejecuta el circuito cuántico para cada muestra del batch\n",
    "        \n",
    "        Args:\n",
    "            x: Tensor de forma (batch_size, n_features)\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(x)\n",
    "        ctx.kernel = kernel\n",
    "        ctx.hamiltonian = hamiltonian\n",
    "        ctx.n_features = n_features\n",
    "        ctx.n_outputs_quantum = n_outputs_quantum\n",
    "        \n",
    "        batch_exp_vals = []\n",
    "        \n",
    "        # Procesar cada muestra del batch por separado\n",
    "        for i in range(x.shape[0]):\n",
    "            # ✅ CORRECTO: Convertir a lista de floats\n",
    "            # x[i] tiene forma (n_features,) después de detach()\n",
    "            single_input = x[i].detach().cpu().numpy()  # Numpy array\n",
    "            single_input_list = single_input.tolist()   # Convertir a lista Python\n",
    "            \n",
    "            # Verificar que es una lista\n",
    "            print(f\"Muestra {i}: tipo={type(single_input_list)}, valor={single_input_list[:3]}...\")\n",
    "            \n",
    "            try:\n",
    "                # Ejecutar el circuito cuántico\n",
    "                result = cudaq.observe(kernel, hamiltonian, single_input_list)\n",
    "                \n",
    "                # Extraer valores de expectación\n",
    "                exp_vals = result.get_expectation_values()\n",
    "                batch_exp_vals.append(float(exp_vals[0]))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando muestra {i}: {e}\")\n",
    "                raise\n",
    "        \n",
    "        output = torch.tensor(batch_exp_vals, \n",
    "                            dtype=x.dtype, \n",
    "                            device=x.device)\n",
    "        return output.unsqueeze(1)  # Asegurar forma correcta: (batch_size, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"Gradiente numérico aproximado\"\"\"\n",
    "        return None, None, None, None, None\n",
    "\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    \"\"\"Capa que encapsula la función cuántica\"\"\"\n",
    "    \n",
    "    def __init__(self, n_features: int, n_outputs_quantum: int):\n",
    "        super(QuantumLayer, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_outputs_quantum = n_outputs_quantum\n",
    "        \n",
    "        # Obtener el kernel usando la factory function\n",
    "        self.kernel = create_quantum_kernel(n_features)\n",
    "        \n",
    "        # Definir el Hamiltoniano (observable)\n",
    "        self.hamiltonian = sum(spin.z(i) for i in range(n_features))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Ejecuta el circuito cuántico para cada muestra\n",
    "        \n",
    "        Args:\n",
    "            x: Tensor de entrada con forma (batch_size, n_features)\n",
    "            \n",
    "        Returns:\n",
    "            Tensor de valores de expectación con forma (batch_size, 1)\n",
    "        \"\"\"\n",
    "        return QuantumFunction.apply(x, self.kernel, self.hamiltonian, \n",
    "                                     self.n_features, self.n_outputs_quantum)\n",
    "\n",
    "class HybridCNN(nn.Module):\n",
    "    \"\"\"Red Neuronal Híbrida: CNN Clásica + Capa Cuántica\"\"\"\n",
    "    def __init__(self, n_qubits: int = 4):\n",
    "        super(HybridCNN, self).__init__()\n",
    "        \n",
    "        # Parte clásica: Convoluciones\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        # Aplanador\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Capa densa antes de lo cuántico\n",
    "        self.pre_quantum_fc = nn.Linear(64 * 5 * 5, n_qubits)\n",
    "        \n",
    "        # Capa cuántica\n",
    "        self.quantum_layer = QuantumLayer(n_features=n_qubits, \n",
    "                                         n_outputs_quantum=n_qubits)\n",
    "        \n",
    "        # Capa densa después de lo cuántico\n",
    "        self.post_quantum_fc = nn.Linear(n_qubits, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Características clásicas\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Reducción a características cuánticas\n",
    "        x = self.pre_quantum_fc(x)\n",
    "        x = torch.sigmoid(x)  # Normalizar entrada cuántica\n",
    "        \n",
    "        # Procesamiento cuántico\n",
    "        x = self.quantum_layer(x)\n",
    "        \n",
    "        # Clasificación final\n",
    "        logits = self.post_quantum_fc(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Crear instancia del modelo híbrido\n",
    "hybrid_model = HybridCNN(n_qubits=4).to(device)\n",
    "print(\"\\n--- Arquitectura del Modelo Híbrido ---\")\n",
    "print(hybrid_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ba130a2-392d-4f50-bb18-852413f7bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 1, 28, 28])\n",
      "Muestra 0: tipo=<class 'list'>, valor=[0.47200697660446167, 0.47281649708747864, 0.4795275330543518]...\n",
      "\u001b[1mError procesando muestra 0: \u001b[91merror: \u001b[0m\u001b[1mInvalid runtime argument type. Argument of type <class 'float'> was provided, but list[float] was expected.\u001b[0m\n",
      "\n",
      "Offending code:\n",
      "  File \"/home/ec2-user/anaconda3/envs/Braket/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "\n",
      "❌ Error: \u001b[91merror: \u001b[0m\u001b[1mInvalid runtime argument type. Argument of type <class 'float'> was provided, but list[float] was expected.\u001b[0m\n",
      "\n",
      "Offending code:\n",
      "  File \"/home/ec2-user/anaconda3/envs/Braket/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeError: \u001b[91merror: \u001b[0m\u001b[1mInvalid runtime argument type. Argument of type <class 'float'> was provided, but list[float] was expected.\u001b[0m\n",
      "\n",
      "Offending code:\n",
      "  File \"/home/ec2-user/anaconda3/envs/Braket/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test de validación\n",
    "test_input = torch.randn(2, 1, 28, 28).to(device)\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "\n",
    "try:\n",
    "    output = hybrid_model(test_input)\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(\"✅ Modelo híbrido funciona correctamente!\")\n",
    "    print(f\"Output logits:\\n{output}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-train-markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo Híbrido\n",
    "\n",
    "Ahora, entrenaremos el modelo híbrido usando el mismo bucle de entrenamiento que para el modelo clásico. Notarás que el entrenamiento puede ser más lento debido a la simulación de los circuitos cuánticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hybrid-train-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Entrenamiento del Modelo Híbrido con MNIST ---\n",
      "Época 1\n",
      "-------------------------------\n",
      "Entrenando (Híbrido)...\n",
      "\u001b[1mError procesando muestra 0: 2151397300.py:5: \u001b[91merror: \u001b[0m\u001b[1mlist argument annotation must provide element type, e.g. list[float] instead of list.\n",
      "\t (offending source -> list)\u001b[0m\n"
     ]
    },
    {
     "ename": "CompilerError",
     "evalue": "2151397300.py:5: \u001b[91merror: \u001b[0m\u001b[1mlist argument annotation must provide element type, e.g. list[float] instead of list.\n\t (offending source -> list)\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCompilerError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÉpoca \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrenando (Híbrido)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhybrid_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn_hybrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_hybrid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidando (Híbrido)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m validation_loop(val_loader, hybrid_model, loss_fn_hybrid)\n",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      5\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[21], line 135\u001b[0m, in \u001b[0;36mHybridCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    132\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(x)  \u001b[38;5;66;03m# Normalizar entrada cuántica a [0, 1]\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Procesamiento cuántico\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantum_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Clasificación final\u001b[39;00m\n\u001b[1;32m    138\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_quantum_fc(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[21], line 93\u001b[0m, in \u001b[0;36mQuantumLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    Ejecuta el circuito cuántico para cada muestra\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m        Tensor de valores de expectación\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQuantumFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhamiltonian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_outputs_quantum\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/torch/autograd/function.py:581\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    589\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[21], line 47\u001b[0m, in \u001b[0;36mQuantumFunction.forward\u001b[0;34m(ctx, x, kernel, hamiltonian, n_features, n_outputs_quantum)\u001b[0m\n\u001b[1;32m     43\u001b[0m single_input \u001b[38;5;241m=\u001b[39m x[i]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Convertir a numpy\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Ejecutar el circuito cuántico\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcudaq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhamiltonian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Extraer valores de expectación\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     exp_vals \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mget_expectation_values()\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/cudaq/runtime/observe.py:72\u001b[0m, in \u001b[0;36mobserve\u001b[0;34m(kernel, spin_operator, shots_count, noise_model, num_trajectories, execution, *args)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mobserve\u001b[39m(kernel,\n\u001b[1;32m     33\u001b[0m             spin_operator,\n\u001b[1;32m     34\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m             num_trajectories\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     38\u001b[0m             execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the expected value of the `spin_operator` with respect to \u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03mthe `kernel`. If the input `spin_operator` is a list of `SpinOperator` then compute \u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03mthe expected value of every operator in the list and return a list of results.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    :class:`ObserveResult` will also contain a :class:`SampleResult` dictionary.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     validityCheck \u001b[38;5;241m=\u001b[39m \u001b[43mcudaq_runtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misValidObserveKernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validityCheck[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobserve specification violated for \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     75\u001b[0m                            kernel\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m validityCheck[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/cudaq/kernel/kernel_decorator.py:214\u001b[0m, in \u001b[0;36mPyKernelDecorator.compile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapturedDataStorage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreateStorage()\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Caches the module and stores captured data into `self.capturedDataStorage`.\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margTypes, extraMetadata \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_to_mlir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastModule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapturedDataStorage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturnType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturnType\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparentVariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobalScopedVars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Grab the dependent capture variables, if any\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependentCaptures \u001b[38;5;241m=\u001b[39m extraMetadata[\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdependent_captures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdependent_captures\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m extraMetadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/cudaq/kernel/ast_bridge.py:4654\u001b[0m, in \u001b[0;36mcompile_to_mlir\u001b[0;34m(astModule, capturedDataStorage, **kwargs)\u001b[0m\n\u001b[1;32m   4648\u001b[0m         PyASTBridge(capturedDataStorage,\n\u001b[1;32m   4649\u001b[0m                     existingModule\u001b[38;5;241m=\u001b[39mbridge\u001b[38;5;241m.\u001b[39mmodule,\n\u001b[1;32m   4650\u001b[0m                     locationOffset\u001b[38;5;241m=\u001b[39mdepKernels[funcName][\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mvisit(\n\u001b[1;32m   4651\u001b[0m                         depKernels[funcName][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   4653\u001b[0m \u001b[38;5;66;03m# Build the MLIR Module for this kernel\u001b[39;00m\n\u001b[0;32m-> 4654\u001b[0m \u001b[43mbridge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mastModule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   4657\u001b[0m     \u001b[38;5;28mprint\u001b[39m(bridge\u001b[38;5;241m.\u001b[39mmodule)\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/cudaq/kernel/ast_bridge.py:1075\u001b[0m, in \u001b[0;36mPyASTBridge.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_msg(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Visit \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, node)\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent_level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/ast.py:418\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    416\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m node\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    417\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/cudaq/kernel/ast_bridge.py:1084\u001b[0m, in \u001b[0;36mPyASTBridge.generic_visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m value:\n\u001b[1;32m   1083\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, ast\u001b[38;5;241m.\u001b[39mAST):\n\u001b[0;32m-> 1084\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ast\u001b[38;5;241m.\u001b[39mAST):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisit(value)\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/cudaq/kernel/ast_bridge.py:1075\u001b[0m, in \u001b[0;36mPyASTBridge.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_msg(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Visit \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, node)\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent_level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/ast.py:418\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    416\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m node\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    417\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/cudaq/kernel/ast_bridge.py:1130\u001b[0m, in \u001b[0;36mPyASTBridge.visit_FunctionDef\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocstring \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mget_docstring(node)\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# Get the argument types and argument names\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;66;03m# this will throw an error if the types aren't annotated\u001b[39;00m\n\u001b[0;32m-> 1130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margTypes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlirTypeFromAnnotation(arg\u001b[38;5;241m.\u001b[39mannotation)\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m   1133\u001b[0m ]\n\u001b[1;32m   1134\u001b[0m parentResultType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknownResultType\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mreturns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1136\u001b[0m         node\u001b[38;5;241m.\u001b[39mreturns, ast\u001b[38;5;241m.\u001b[39mConstant) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m                                      (node\u001b[38;5;241m.\u001b[39mreturns\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/cudaq/kernel/ast_bridge.py:1131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocstring \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mget_docstring(node)\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;66;03m# Get the argument types and argument names\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;66;03m# this will throw an error if the types aren't annotated\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margTypes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 1131\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlirTypeFromAnnotation\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mannotation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m   1133\u001b[0m ]\n\u001b[1;32m   1134\u001b[0m parentResultType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknownResultType\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mreturns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1136\u001b[0m         node\u001b[38;5;241m.\u001b[39mreturns, ast\u001b[38;5;241m.\u001b[39mConstant) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m                                      (node\u001b[38;5;241m.\u001b[39mreturns\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/cudaq/kernel/ast_bridge.py:853\u001b[0m, in \u001b[0;36mPyASTBridge.mlirTypeFromAnnotation\u001b[0;34m(self, annotation)\u001b[0m\n\u001b[1;32m    850\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 853\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memitFatalError\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Braket/lib/python3.10/site-packages/cudaq/kernel/ast_bridge.py:243\u001b[0m, in \u001b[0;36mPyASTBridge.emitFatalError\u001b[0;34m(self, msg, astNode)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mprint\u001b[39m(Color\u001b[38;5;241m.\u001b[39mBOLD, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    238\u001b[0m msg \u001b[38;5;241m=\u001b[39m codeFile \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[1;32m    239\u001b[0m     lineNumber\n\u001b[1;32m    240\u001b[0m ) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m Color\u001b[38;5;241m.\u001b[39mRED \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m Color\u001b[38;5;241m.\u001b[39mEND \u001b[38;5;241m+\u001b[39m Color\u001b[38;5;241m.\u001b[39mBOLD \u001b[38;5;241m+\u001b[39m msg \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m (offending source -> \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m ast\u001b[38;5;241m.\u001b[39munparse(astNode) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(ast, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munparse\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m astNode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m Color\u001b[38;5;241m.\u001b[39mEND\n\u001b[0;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m CompilerError(msg)\n",
      "\u001b[0;31mCompilerError\u001b[0m: 2151397300.py:5: \u001b[91merror: \u001b[0m\u001b[1mlist argument annotation must provide element type, e.g. list[float] instead of list.\n\t (offending source -> list)\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Definir la función de pérdida y el optimizador para el modelo híbrido\n",
    "loss_fn_hybrid = nn.CrossEntropyLoss()\n",
    "optimizer_hybrid = optim.Adam(hybrid_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Bucle principal de entrenamiento para el modelo híbrido\n",
    "epochs = 10\n",
    "print(\"\\n--- Iniciando Entrenamiento del Modelo Híbrido con MNIST ---\")\n",
    "for t in range(epochs):\n",
    "    print(f\"Época {t+1}\\n-------------------------------\")\n",
    "    print(\"Entrenando (Híbrido)...\")\n",
    "    train_loop(train_loader, hybrid_model, loss_fn_hybrid, optimizer_hybrid)\n",
    "    print(\"Validando (Híbrido)...\")\n",
    "    validation_loop(val_loader, hybrid_model, loss_fn_hybrid)\n",
    "print(\"¡Entrenamiento híbrido finalizado!\")\n",
    "\n",
    "# Evaluar el modelo híbrido en el conjunto de prueba\n",
    "print(\"\\n--- Evaluando Modelo Híbrido con el conjunto de Prueba (Test) ---\")\n",
    "validation_loop(test_loader, hybrid_model, loss_fn_hybrid)\n",
    "\n",
    "# Guardar los pesos del modelo híbrido entrenado\n",
    "save_model(hybrid_model, \"hybrid_cnn_mnist_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0130826f-dd7d-4405-b508-1fd89f418026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_braket",
   "language": "python",
   "name": "conda_braket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
