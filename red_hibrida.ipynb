{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6eebc8",
   "metadata": {},
   "source": [
    "# Redes neuronales hibridas  para clasificación multiple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1f1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9a63f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/anaconda3/envs/Braket/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/ec2-user/anaconda3/envs/Braket/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/Braket/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/Braket/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/Braket/lib/python3.10/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/Braket/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/Braket/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m?\u001b[0m  \u001b[33m0:02:45\u001b[0meta \u001b[36m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m217.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m  \u001b[33m0:00:16\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m155.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.3/170.3 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.24.1-cp310-cp310-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m137.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m144.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m196.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/22\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: sympy 1.12.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/22\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling sympy-1.12.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/22\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.12.1━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/22\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/22\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.9.86\u001b[0m \u001b[32m 4/22\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.9.86:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/22\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.86━━\u001b[0m \u001b[32m 4/22\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/22\u001b[0m [nvidia-nccl-cu12]cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.10.19\u001b[0m \u001b[32m 6/22\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.10.19:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/22\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.10.19━━\u001b[0m \u001b[32m 6/22\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/22\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.9.79m \u001b[32m 7/22\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.9.79:━━━━━━━━━━━━\u001b[0m \u001b[32m 7/22\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.9.79[0m \u001b[32m 7/22\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/22\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.9.86[0m \u001b[32m 9/22\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.9.86:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/22\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.9.86━\u001b[0m \u001b[32m 9/22\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/22\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.9.1.4━━\u001b[0m \u001b[32m11/22\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.9.1.4:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/22\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.9.1.4━━━━━━━━\u001b[0m \u001b[32m12/22\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/22\u001b[0m [fsspec]cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.10.650m \u001b[32m13/22\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.10.65:━━━━━━━━━━━━━\u001b[0m \u001b[32m13/22\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.10.65\u001b[0m \u001b[32m13/22\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu1291m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m17/22\u001b[0m [nvidia-cudnn-cu12]12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.5.82[0m \u001b[32m17/22\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.5.82:\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m17/22\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.5.82━\u001b[0m \u001b[32m17/22\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/22\u001b[0m [torchaudio]2\u001b[0m [torchaudio]]ver-cu12]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "amazon-braket-algorithm-library 1.6.2 requires sympy<1.13, but you have sympy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed filelock-3.20.0 fsspec-2025.10.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.9.1 torchaudio-2.9.1 torchvision-0.24.1 triton-3.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the relevant packages.\n",
    "#%pip install --upgrade pip\n",
    "%pip install torch torchvision torchaudio\n",
    "#%pip install cudaq -> ya viene instalado en el braket de AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50673393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.19 | packaged by conda-forge | (main, Oct 22 2025, 22:29:10) [GCC 14.3.0]\n",
      "NumPy version: 1.26.4\n",
      "Matplotlib version: 3.10.7\n",
      "torch: 2.9.1+cu128\n",
      "vision: 0.24.1+cu128\n",
      "audio: 2.9.1+cu128\n"
     ]
    }
   ],
   "source": [
    "# Check installed clasico\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "\n",
    "import torch, torchvision, torchaudio\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"vision:\", torchvision.__version__)\n",
    "print(\"audio:\", torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5318ca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDAQ version: CUDA-Q Version 0.12.0 (https://github.com/NVIDIA/cuda-quantum 6adf92bcda4df7465e4fe82f1c8f782ae69d8bd2)\n",
      "Running on target: qpp-cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cudaq\n",
    "print(f\"CUDAQ version: {cudaq.__version__}\")\n",
    "print(f\"Running on target: {cudaq.get_target().name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cudaq\n",
    "\n",
    "print(f\"Running on target {cudaq.get_target().name}\")\n",
    "qubit_count = int(sys.argv[1]) if 1 < len(sys.argv) else 2\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel():\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "    h(qubits[0])\n",
    "    for i in range(1, qubit_count):\n",
    "        x.ctrl(qubits[0], qubits[i])\n",
    "    mz(qubits)\n",
    "\n",
    "\n",
    "result = cudaq.sample(kernel)\n",
    "print(result)  # Example: { 11:500 00:500 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918cbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar las librerías necesarias\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Para asegurar que los resultados sean reproducibles\n",
    "torch.manual_seed(42)\n",
    "\n",
    "cudaq.set_random_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582043a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el dispositivo\n",
    "# Set CUDAQ and PyTorch to run on either CPU or GPU.\n",
    "\n",
    "device = torch.device('cpu')\n",
    "cudaq.set_target(\"qpp-cpu\")\n",
    "\n",
    "#cudaq.set_target(\"nvidia\")\n",
    "#device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13cbb16",
   "metadata": {},
   "source": [
    "## Descripción del Conjunto de Datos MNIST\n",
    "\n",
    "- *¿Qué es?:* MNIST (Modified National Institute of Standards and Technology database) es una gran base de datos de dígitos escritos a mano, del 0 al 9.\n",
    "- *Contenido:* Contiene 70,000 imágenes en escala de grises.\n",
    "- *Conjunto de entrenamiento:* 60,000 imágenes.\n",
    "- *Conjunto de prueba:* 10,000 imágenes.\n",
    "- *Formato de imagen:* Cada imagen tiene un tamaño de 28x28 píxeles.\n",
    "- *Uso común:* Es considerado el \"Hola, Mundo\" de la visión por computadora y el aprendizaje profundo. Se utiliza para entrenar y probar algoritmos de clasificación de imágenes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeaf4a4",
   "metadata": {},
   "source": [
    "Paso 2: Cargar, Transformar y Previsualizar los Datos\n",
    "torchvision nos facilita la descarga y preparación de datasets.\n",
    "\n",
    "Transformaciones: Convertimos las imágenes a tensores de PyTorch y las normalizamos. La normalización (ajustar los valores de los píxeles para que tengan una media de 0.5 y una desviación estándar de 0.5) ayuda a que el modelo entrene más rápido y de forma más estable.\n",
    "Descarga: Descargamos los conjuntos de entrenamiento y prueba. FashionMNIST ya viene separado en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definir las transformaciones para las imágenes\n",
    "# - transforms.ToTensor() convierte la imagen (PIL) a un Tensor de PyTorch.\n",
    "# - transforms.Normalize() ajusta los valores del tensor para que tengan una media y desviación estándar específicas.\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Media y Desviación Estándar para un solo canal (escala de grises)\n",
    "])\n",
    "\n",
    "# 2. Descargar los datasets de entrenamiento y prueba\n",
    "train_full_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Tamaño total del dataset de entrenamiento: {len(train_full_dataset)}\")\n",
    "print(f\"Tamaño del dataset de prueba: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MODIFICACIÓN: Usar solo 1000 muestras para una prueba rápida ---\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# 1. Creamos un subconjunto con las primeras 1000 imágenes del dataset de entrenamiento completo\n",
    "n_samples_prueba = 1000\n",
    "train_subset_for_testing = Subset(train_full_dataset, range(n_samples_prueba))\n",
    "\n",
    "# 2. Ahora, basamos la división 80/20 en este subconjunto de 1000 muestras\n",
    "train_size = int(0.8 * len(train_subset_for_testing)) # 80% de 1000 = 800\n",
    "val_size = len(train_subset_for_testing) - train_size # 20% de 1000 = 200\n",
    "\n",
    "# Dividimos el dataset de entrenamiento\n",
    "train_dataset, val_dataset = random_split(train_subset_for_testing, [train_size, val_size])\n",
    "\n",
    "print(f\"Tamaño del subconjunto de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"Tamaño del subconjunto de validación: {len(val_dataset)}\")\n",
    "\n",
    "# Crear los DataLoaders\n",
    "# Los DataLoaders nos permiten iterar sobre los datos en lotes (batches)\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clases de MNIST (dígitos del 0 al 9)\n",
    "classes = tuple(str(i) for i in range(10))\n",
    "\n",
    "# Función para mostrar imágenes (sin cambios)\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Des-normalizar\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Obtener un lote de imágenes de entrenamiento\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Mostrar las primeras 8 imágenes y sus etiquetas\n",
    "print(\"--- Previsualización de Datos (MNIST) ---\")\n",
    "imshow(torchvision.utils.make_grid(images[:8]))\n",
    "print('Etiquetas: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Arquitectura del Modelo ---\n",
      "CNN(\n",
      "  (conv_stack): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc_stack): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=1600, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Bloque convolucional para extracción de características\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            # Entrada: 1x28x28 -> Salida: 32x26x26\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            # Entrada: 32x26x26 -> Salida: 32x13x13\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # Entrada: 32x13x13 -> Salida: 64x11x11\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            # Entrada: 64x11x11 -> Salida: 64x5x5\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        # Aplanador y clasificador\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_stack = nn.Sequential(\n",
    "            # Previene el sobreajuste\n",
    "            nn.Dropout(0.5),\n",
    "            # Mapea las características a las 10 clases de salida\n",
    "            # La entrada es 64*5*5 = 1600\n",
    "            nn.Linear(64 * 5 * 5, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pasa la imagen por las capas convolucionales\n",
    "        x = self.conv_stack(x)\n",
    "        # Aplana el resultado para la capa densa\n",
    "        x = self.flatten(x)\n",
    "        # Pasa por el clasificador final\n",
    "        logits = self.fc_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Instanciamos el modelo y lo movemos al dispositivo (GPU/CPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CNN().to(device)\n",
    "print(\"\\n--- Arquitectura del Modelo ---\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a871d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Pérdida (loss): {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    val_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            val_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Resultado: \\n Precisión (Accuracy): {(100*correct):>0.1f}%, Pérdida promedio: {val_loss:>8f} \\n\")\n",
    "\n",
    "# Bucle principal de entrenamiento\n",
    "epochs = 10\n",
    "print(\"\\n--- Iniciando Entrenamiento con MNIST ---\")\n",
    "for t in range(epochs):\n",
    "    print(f\"Época {t+1}\\n-------------------------------\")\n",
    "    print(\"Entrenando...\")\n",
    "    train_loop(train_loader, model, loss_fn, optimizer)\n",
    "    print(\"Validando...\")\n",
    "    validation_loop(val_loader, model, loss_fn)\n",
    "print(\"¡Entrenamiento finalizado!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609016cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Evaluando con el conjunto de Prueba (Test) ---\")\n",
    "validation_loop(test_loader, model, loss_fn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_braket",
   "language": "python",
   "name": "conda_braket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
