{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6eebc8",
   "metadata": {},
   "source": [
    "# Redes neuronales hibridas  para clasificación multiple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1f1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the relevant packages.\n",
    "#%pip install --upgrade pip\n",
    "#%pip install torch torchvision torchaudio\n",
    "#%pip install cudaq -> ya viene instalado en el braket de AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50673393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check installed clasico\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "\n",
    "import torch, torchvision, torchaudio\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"vision:\", torchvision.__version__)\n",
    "print(\"audio:\", torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cudaq\n",
    "print(f\"CUDAQ version: {cudaq.__version__}\")\n",
    "print(f\"Running on target: {cudaq.get_target().name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cudaq\n",
    "\n",
    "print(f\"Running on target {cudaq.get_target().name}\")\n",
    "qubit_count = 2\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel():\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "    h(qubits[0])\n",
    "    for i in range(1, qubit_count):\n",
    "        x.ctrl(qubits[0], qubits[i])\n",
    "    mz(qubits)\n",
    "\n",
    "\n",
    "result = cudaq.sample(kernel)\n",
    "print(result)  # Example: { 11:500 00:500 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d874d9c8-a2b1-4553-b0d5-98d1bfb04ae3",
   "metadata": {},
   "source": [
    "### Configuración de Hiperparámetros\n",
    "\n",
    "Para facilitar la experimentación, todos los hiperparámetros importantes se definen en la siguiente celda. Puedes modificar estos valores para ver cómo afectan el rendimiento y el tiempo de entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd250776-108f-4571-8003-b00e008be7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hiperparámetros del Modelo y Entrenamiento ---\n",
    "# Configurados para la versión reducida del HQNN (4x4 -> 16 qubits, 45 compuertas ZZ en 3 capas)\n",
    "n_qubits = 16\n",
    "pqc_layers = 3  # Tres capas de tipo escalera: (n_qubits - 1) compuertas por capa = 45 en total\n",
    "n_samples_prueba = 1000  # Usa el dataset completo de MNIST reducido; ajusta si quieres pruebas rápidas\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "learning_rate = 5e-4  # LR bajo para estabilizar el entrenamiento mixto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918cbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar las librerías necesarias\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Para asegurar que los resultados sean reproducibles\n",
    "torch.manual_seed(33)\n",
    "\n",
    "cudaq.set_random_seed(33)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582043a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el dispositivo\n",
    "# Set CUDAQ and PyTorch to run on either CPU or GPU.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    cudaq.set_target(\"nvidia\")\n",
    "    print(\"✅ Dispositivo configurado para GPU (CUDA).\")\n",
    "else:\n",
    "    cudaq.set_target(\"qpp-cpu\")\n",
    "    print(\"⚠️ GPU no encontrada. Usando CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13cbb16",
   "metadata": {},
   "source": [
    "## Descripción del Conjunto de Datos MNIST\n",
    "\n",
    "- *¿Qué es?:* MNIST (Modified National Institute of Standards and Technology database) es una gran base de datos de dígitos escritos a mano, del 0 al 9.\n",
    "- *Contenido:* Contiene 70,000 imágenes en escala de grises.\n",
    "- *Conjunto de entrenamiento:* 60,000 imágenes.\n",
    "- *Conjunto de prueba:* 10,000 imágenes.\n",
    "- *Formato de imagen:* Cada imagen tiene un tamaño de 28x28 píxeles.\n",
    "- *Uso común:* Es considerado el \"Hola, Mundo\" de la visión por computadora y el aprendizaje profundo. Se utiliza para entrenar y probar algoritmos de clasificación de imágenes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeaf4a4",
   "metadata": {},
   "source": [
    "Paso 2: Cargar, Transformar y Previsualizar los Datos\n",
    "torchvision nos facilita la descarga y preparación de datasets.\n",
    "\n",
    "Transformaciones: Convertimos las imágenes a tensores de PyTorch y las normalizamos. La normalización (ajustar los valores de los píxeles para que tengan una media de 0.5 y una desviación estándar de 0.5) ayuda a que el modelo entrene más rápido y de forma más estable.\n",
    "Descarga: Descargamos los conjuntos de entrenamiento y prueba. FashionMNIST ya viene separado en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación 4x4 inspirada en la reducción del paper (Figura 2)\n",
    "# 1) Normaliza a [0,1] con ToTensor\n",
    "# 2) Recorta 4 píxeles por lado (28 -> 20)\n",
    "# 3) Promedia cada bloque 5x5 para obtener una imagen 4x4\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda t: t[:, 4:-4, 4:-4]),\n",
    "    transforms.Lambda(lambda t: F.avg_pool2d(t, kernel_size=5, stride=5)),\n",
    "])\n",
    "\n",
    "# Descargar los datasets de entrenamiento y prueba con la transformación reducida\n",
    "train_full_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Tamaño total del dataset de entrenamiento: {len(train_full_dataset)}\")\n",
    "print(f\"Tamaño del dataset de prueba: {len(test_dataset)}\")\n",
    "print(f\"Dimensión tras reducción: {train_full_dataset[0][0].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subconjunto configurable (por defecto se usa todo el dataset de entrenamiento reducido)\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_subset_for_testing = Subset(train_full_dataset, range(n_samples_prueba))\n",
    "\n",
    "train_size = int(0.8 * len(train_subset_for_testing))\n",
    "val_size = len(train_subset_for_testing) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_subset_for_testing, [train_size, val_size])\n",
    "\n",
    "print(f\"Tamaño del subconjunto de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"Tamaño del subconjunto de validación: {len(val_dataset)}\")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clases de MNIST (dígitos del 0 al 9)\n",
    "classes = tuple(str(i) for i in range(10))\n",
    "\n",
    "# Función para mostrar imágenes reducidas\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.squeeze(np.transpose(npimg, (1, 2, 0))), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Obtener un lote de imágenes de entrenamiento\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Mostrar las primeras 8 imágenes reducidas\n",
    "imshow(torchvision.utils.make_grid(images[:8], nrow=8))\n",
    "print('Etiquetas: ', ' '.join(f'{classes[labels[j]]}' for j in range(8)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb2cf2-d5f8-4fd1-a150-a0715a1a9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Guardar los pesos del modelo entrenado (con versionado) ---\n",
    "import os\n",
    "\n",
    "def save_model(model, base_name):\n",
    "    \"\"\"\n",
    "    Guarda el modelo. Si ya existe un archivo con el mismo nombre base,\n",
    "    crea una nueva versión (ej. _v2.0.pth, _v3.0.pth, etc.).\n",
    "    \"\"\"\n",
    "    # Construye el nombre del archivo base\n",
    "    file_path = f\"{base_name}.pth\"\n",
    "\n",
    "    # Si el archivo base no existe, lo guarda con ese nombre y termina.\n",
    "    if not os.path.exists(file_path):\n",
    "        torch.save(model.state_dict(), file_path)\n",
    "        print(f\"¡Modelo guardado exitosamente en {file_path}!\")\n",
    "        return\n",
    "\n",
    "    # Si el archivo base ya existe, busca la siguiente versión disponible.\n",
    "    version = 2\n",
    "    while True:\n",
    "        # Creamos el nombre de archivo versionado (ej: hybrid_cnn_mnist_weights_v2.0.pth)\n",
    "        # Usamos un guion bajo en lugar de \":\" para compatibilidad con el sistema de archivos.\n",
    "        versioned_path = f\"{base_name}_v{version:.1f}.pth\"\n",
    "        \n",
    "        # Si no existe un archivo con ese nombre de versión, lo guardamos y salimos del bucle.\n",
    "        if not os.path.exists(versioned_path):\n",
    "            torch.save(model.state_dict(), versioned_path)\n",
    "            print(f\"¡Modelo guardado exitosamente en {versioned_path}!\")\n",
    "            break\n",
    "        \n",
    "        # Si ya existe, incrementamos la versión y volvemos a intentarlo.\n",
    "        version += 1\n",
    "\n",
    "# Ejemplo de cómo se llamaría (no es necesario que cambies esto en la celda de entrenamiento):\n",
    "# save_model(model, \"cnn_mnist_weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hyperparameters-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hiperparámetros del Modelo y Entrenamiento ---\n",
    "# Configurados para la versión reducida del HQNN (4x4 -> 16 qubits, 45 compuertas ZZ en 3 capas)\n",
    "n_qubits = 16\n",
    "pqc_layers = 3  # Tres capas de tipo escalera: (n_qubits - 1) compuertas por capa = 45 en total\n",
    "n_samples_prueba = 60000  # Usa el dataset completo de MNIST reducido; ajusta si quieres pruebas rápidas\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "learning_rate = 5e-4  # LR bajo para estabilizar el entrenamiento mixto\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd9cb5-5e94-40f2-9ede-5a9ce6e0bc0c",
   "metadata": {},
   "source": [
    "## Implementación del Modelo Híbrido Cuántico-Clásico\n",
    "\n",
    "Ahora, construiremos y entrenaremos el modelo híbrido. Este modelo combinará capas convolucionales clásicas para la extracción de características con un circuito cuántico parametrizado para el procesamiento de la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c47104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "from cudaq import spin\n",
    "\n",
    "# Configuración del circuito inspirada en el HQNN reducido del paper\n",
    "ladder_depth = pqc_layers\n",
    "n_thetas = (n_qubits - 1) * ladder_depth\n",
    "\n",
    "# Kernel con datos (ángulos) + parámetros entrenables del PQC\n",
    "theta_kernel, (data_params, theta_params) = cudaq.make_kernel(list, list)\n",
    "qubits = theta_kernel.qalloc(n_qubits)\n",
    "\n",
    "# Codificación con RY (usa ángulos preprocesados con arcsin en la parte clásica)\n",
    "for i in range(n_qubits):\n",
    "    theta_kernel.ry(data_params[i], qubits[i])\n",
    "\n",
    "# PQC en escalera: compuertas ZZ parametrizadas (decompuestas en CX-RZ-CX)\n",
    "theta_index = 0\n",
    "for _ in range(ladder_depth):\n",
    "    for j in range(n_qubits - 1):\n",
    "        theta_kernel.cx(qubits[j], qubits[j + 1])\n",
    "        theta_kernel.rz(2 * theta_params[theta_index], qubits[j + 1])\n",
    "        theta_kernel.cx(qubits[j], qubits[j + 1])\n",
    "        theta_index += 1\n",
    "\n",
    "# Medición All-qubit Multi-observable (X, Y, Z en todos los qubits)\n",
    "measurement_ops = []\n",
    "for op in (spin.x, spin.y, spin.z):\n",
    "    for q in range(n_qubits):\n",
    "        measurement_ops.append(op(q))\n",
    "\n",
    "\n",
    "def evaluate_expectations(sample_angles, theta_values):\n",
    "    \"\"\"Ejecuta el kernel y devuelve <X|Y|Z> de cada qubit.\"\"\"\n",
    "    obs_results = []\n",
    "    for obs in measurement_ops:\n",
    "        res = cudaq.observe(theta_kernel, obs, sample_angles, theta_values)\n",
    "        obs_results.append(res.expectation())\n",
    "    return obs_results\n",
    "\n",
    "\n",
    "class QuantumFunction(Function):\n",
    "    \"\"\"Autograd manual con parameter-shift para datos y parámetros del PQC.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, data: torch.Tensor, thetas: torch.Tensor):\n",
    "        ctx.save_for_backward(data, thetas)\n",
    "        theta_list = thetas.detach().cpu().tolist()\n",
    "        batch_results = []\n",
    "        for row in data:\n",
    "            sample_angles = row.detach().cpu().tolist()\n",
    "            batch_results.append(evaluate_expectations(sample_angles, theta_list))\n",
    "        return torch.tensor(batch_results, device=data.device, dtype=data.dtype)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: torch.Tensor):\n",
    "        data, thetas = ctx.saved_tensors\n",
    "        batch_size, n_features = data.shape\n",
    "        theta_list = thetas.detach().cpu().tolist()\n",
    "        shift = np.pi / 2.0\n",
    "\n",
    "        def batch_expectations(data_tensor, theta_values):\n",
    "            results = []\n",
    "            for row in data_tensor:\n",
    "                results.append(evaluate_expectations(row.detach().cpu().tolist(), theta_values))\n",
    "            return torch.tensor(results, device=data.device, dtype=data.dtype)\n",
    "\n",
    "        gradients_x = torch.zeros_like(data)\n",
    "        for idx in range(n_features):\n",
    "            x_plus = data.clone()\n",
    "            x_minus = data.clone()\n",
    "            x_plus[:, idx] += shift\n",
    "            x_minus[:, idx] -= shift\n",
    "            exp_plus = batch_expectations(x_plus, theta_list)\n",
    "            exp_minus = batch_expectations(x_minus, theta_list)\n",
    "            gradient_component = 0.5 * (exp_plus - exp_minus)\n",
    "            gradients_x[:, idx] = (gradient_component * grad_output).sum(dim=1)\n",
    "\n",
    "        gradients_theta = torch.zeros_like(thetas)\n",
    "        for t_idx in range(len(theta_list)):\n",
    "            theta_plus = theta_list.copy()\n",
    "            theta_minus = theta_list.copy()\n",
    "            theta_plus[t_idx] += shift\n",
    "            theta_minus[t_idx] -= shift\n",
    "            exp_plus = batch_expectations(data, theta_plus)\n",
    "            exp_minus = batch_expectations(data, theta_minus)\n",
    "            gradient_component = 0.5 * (exp_plus - exp_minus)\n",
    "            gradients_theta[t_idx] = (gradient_component * grad_output).sum()\n",
    "\n",
    "        return gradients_x, gradients_theta\n",
    "\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    \"\"\"Capa cuántica con parámetros entrenables del PQC (45 compuertas en total).\"\"\"\n",
    "    def __init__(self, n_qubits: int, ladder_depth: int):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.ladder_depth = ladder_depth\n",
    "        self.theta = nn.Parameter(torch.zeros((n_qubits - 1) * ladder_depth))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return QuantumFunction.apply(x, self.theta)\n",
    "\n",
    "\n",
    "class HybridHQNN(nn.Module):\n",
    "    \"\"\"Modelo híbrido reducido inspirado en el HQNN del paper.\"\"\"\n",
    "    def __init__(self, n_qubits: int = n_qubits, ladder_depth: int = pqc_layers):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.quantum = QuantumLayer(n_qubits, ladder_depth)\n",
    "        # 3 observables por qubit -> 48 features para 16 qubits\n",
    "        self.classifier = nn.Linear(3 * n_qubits, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # [batch, 16]\n",
    "        x = torch.clamp(x, 0.0, 1.0)\n",
    "        angles = torch.arcsin(x)  # f(x) = arcsin(x) como en el paper\n",
    "        q_out = self.quantum(angles)\n",
    "        logits = self.classifier(q_out)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba130a2-392d-4f50-bb18-852413f7bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Creación y Validación del Modelo ---\n",
    "\n",
    "# Crear instancia del modelo híbrido reducido\n",
    "hybrid_model = HybridHQNN(n_qubits=n_qubits, ladder_depth=pqc_layers).to(device)\n",
    "print(\"--- Arquitectura del Modelo Híbrido (HQNN reducido) ---\")\n",
    "print(hybrid_model)\n",
    "\n",
    "# --- Test de Validación Cuántico-Clásico (Forward y Backward) ---\n",
    "print(\"--- Realizando Test de Validación Cuántico-Clásico ---\")\n",
    "\n",
    "test_input = torch.randn(4, 1, 4, 4).to(device)  # imágenes ya reducidas a 4x4\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "\n",
    "output = hybrid_model(test_input)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(\"✅ Pase hacia adelante completado\")\n",
    "\n",
    "# Pase hacia atrás\n",
    "target = torch.randint(0, 10, (4,)).to(device)\n",
    "loss_fn_test = nn.CrossEntropyLoss()\n",
    "loss = loss_fn_test(output, target)\n",
    "loss.backward()\n",
    "\n",
    "grad_pre_quantum = hybrid_model.classifier.weight.grad\n",
    "if grad_pre_quantum is not None and grad_pre_quantum.abs().sum() > 0:\n",
    "    print(\"✅ Backward funcionando: gradientes fluyen a través del bloque cuántico + clasificador.\")\n",
    "else:\n",
    "    print(\"❌ Error en el backward: sin gradientes en el clasificador.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-train-markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo Híbrido\n",
    "\n",
    "Ahora, entrenaremos el modelo híbrido usando el mismo bucle de entrenamiento que para el modelo clásico. Notarás que el entrenamiento puede ser más lento debido a la simulación de los circuitos cuánticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-train-validation-loops",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definir los bucles de entrenamiento y validación ---\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"Bucle para una época de entrenamiento.\"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() # Poner el modelo en modo de entrenamiento\n",
    "    total_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Mover datos al dispositivo (CPU o GPU)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Calcular la predicción y la pérdida\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn):\n",
    "    \"\"\"Bucle para evaluar el modelo en el conjunto de validación o prueba.\"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() # Poner el modelo en modo de evaluación\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad(): # No necesitamos calcular gradientes aquí\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-train-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Entrenamiento del Modelo Híbrido ---\n",
    "import time\n",
    "# Definir la función de pérdida y el optimizador\n",
    "loss_fn_hybrid = nn.CrossEntropyLoss()\n",
    "optimizer_hybrid = optim.Adam(hybrid_model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# El planificador reducirá el learning rate (lr) en un factor de 0.1 cada 5 épocas.\n",
    "# Esto ayuda a afinar el modelo una vez que el aprendizaje inicial se ralentiza.\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer_hybrid, step_size=10, gamma=0.1)\n",
    "# Listas para almacenar el historial de entrenamiento\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "# Bucle principal de entrenamiento para el modelo híbrido\n",
    "print(\"\\n--- Iniciando Entrenamiento del Modelo Híbrido con MNIST ---\")\n",
    "start_time = time.time()\n",
    "for t in range(epochs):\n",
    "    print(f\"Época {t+1}\\n-------------------------------\")\n",
    "    print(\"Entrenando (Híbrido)...\")\n",
    "    train_loss = train_loop(train_loader, hybrid_model, loss_fn_hybrid, optimizer_hybrid)\n",
    "    print(\"Validando (Híbrido)...\")\n",
    "    val_loss, val_acc = validation_loop(val_loader, hybrid_model, loss_fn_hybrid)\n",
    "    \n",
    "    # Guardar métricas de la época\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "    scheduler.step()\n",
    "\n",
    "end_time = time.time()\n",
    "total_training_time = end_time - start_time\n",
    "print(\"¡Entrenamiento híbrido finalizado!\")\n",
    "\n",
    "# Evaluar el modelo híbrido en el conjunto de prueba\n",
    "print(\"\\n--- Evaluando Modelo Híbrido con el conjunto de Prueba (Test) ---\")\n",
    "validation_loop(test_loader, hybrid_model, loss_fn_hybrid)\n",
    "\n",
    "# Guardar los pesos del modelo híbrido entrenado\n",
    "save_model(hybrid_model, \"hybrid_cnn_mnist_weights_gpu\" if device==\"cuda\" else \"hybrid_cnn_mnist_weights_cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualización de Resultados ---\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Usamos las variables definidas en las celdas anteriores\n",
    "num_epochs = epochs\n",
    "num_train_samples = len(train_dataset)\n",
    "\n",
    "# Determinar el nombre del dispositivo para el título de la gráfica\n",
    "if device == \"cuda\":\n",
    "    device_name = f\"GPU ({torch.cuda.get_device_name(0)})\"\n",
    "else:\n",
    "    device_name = \"CPU\"\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# Título principal de la figura con la nueva información del dispositivo\n",
    "title_text = \"\\n\".join([\n",
    "    \"Modelo Híbrido - Historial de Entrenamiento\",\n",
    "    f\"({num_epochs} épocas en {num_train_samples} muestras) batch_size={batch_size}\",\n",
    "    f\"Ejecutado en: {device_name}\",\n",
    "    f\"Tiempo total de entrenamiento: {total_training_time:.2f} segundos\",\n",
    "])\n",
    "fig.suptitle(title_text, fontsize=16)\n",
    "\n",
    "# Gráfica de Pérdida (Loss)\n",
    "ax1.plot(history['train_loss'], label='Pérdida de Entrenamiento', marker='o')\n",
    "ax1.plot(history['val_loss'], label='Pérdida de Validación', marker='o')\n",
    "ax1.set_ylabel('Pérdida (Loss)')\n",
    "ax1.set_title('Pérdida a lo largo de las Épocas')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Gráfica de Precisión (Accuracy)\n",
    "ax2.plot(history['val_accuracy'], label='Precisión de Validación', color='green', marker='o')\n",
    "ax2.set_xlabel('Épocas')\n",
    "ax2.set_ylabel('Precisión (Accuracy)')\n",
    "ax2.set_title('Precisión de Validación a lo largo de las Épocas')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-random-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "hybrid_model.eval()\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "idx = random.randint(0, len(images) - 1)\n",
    "img = images[idx].unsqueeze(0)\n",
    "true_label = labels[idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = hybrid_model(img)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "img_display = img.cpu().squeeze()\n",
    "plt.imshow(img_display, cmap='gray')\n",
    "plt.title(f\"Etiqueta Real: {classes[true_label]} | Predicción: {classes[predicted.item()]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4e51f-bc3c-4bdf-bfa7-303685cb3d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132a6f4-2866-4e21-b4fb-6b0c0bced3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_braket",
   "language": "python",
   "name": "conda_braket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
