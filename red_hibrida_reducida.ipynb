{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6eebc8",
   "metadata": {},
   "source": [
    "# Redes neuronales hibridas  para clasificaci\u00f3n multiple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1f1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the relevant packages.\n",
    "#%pip install --upgrade pip\n",
    "#%pip install torch torchvision torchaudio\n",
    "#%pip install cudaq -> ya viene instalado en el braket de AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50673393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check installed clasico\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "\n",
    "import torch, torchvision, torchaudio\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"vision:\", torchvision.__version__)\n",
    "print(\"audio:\", torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cudaq\n",
    "print(f\"CUDAQ version: {cudaq.__version__}\")\n",
    "print(f\"Running on target: {cudaq.get_target().name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cudaq\n",
    "\n",
    "print(f\"Running on target {cudaq.get_target().name}\")\n",
    "qubit_count = 2\n",
    "\n",
    "\n",
    "@cudaq.kernel\n",
    "def kernel():\n",
    "    qubits = cudaq.qvector(qubit_count)\n",
    "    h(qubits[0])\n",
    "    for i in range(1, qubit_count):\n",
    "        x.ctrl(qubits[0], qubits[i])\n",
    "    mz(qubits)\n",
    "\n",
    "\n",
    "result = cudaq.sample(kernel)\n",
    "print(result)  # Example: { 11:500 00:500 }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d874d9c8-a2b1-4553-b0d5-98d1bfb04ae3",
   "metadata": {},
   "source": [
    "### Configuraci\u00f3n de Hiperpar\u00e1metros\n",
    "\n",
    "Para facilitar la experimentaci\u00f3n, todos los hiperpar\u00e1metros importantes se definen en la siguiente celda. Puedes modificar estos valores para ver c\u00f3mo afectan el rendimiento y el tiempo de entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd250776-108f-4571-8003-b00e008be7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hiperpar\u00e1metros del Modelo y Entrenamiento ---\n",
    "# Versi\u00f3n ligera: 4 qubits + medici\u00f3n AMM (12 features) + PQC en escalera poco profunda\n",
    "n_qubits = 4\n",
    "pqc_layers = 2  # profundidad baja para reducir llamadas cu\u00e1nticas\n",
    "n_samples_prueba = 12000  # subconjunto para experimentar r\u00e1pido; pon 60000 para todo MNIST reducido\n",
    "batch_size = 64\n",
    "epochs = 15\n",
    "learning_rate = 8e-4  # LR moderado para estabilidad con el bloque cu\u00e1ntico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37087a4",
   "metadata": {},
   "source": [
    "### Estructura del modelo AMM ligero\n",
    "- Entrada: imagen MNIST reducida 4\u00d74 (16 px) -> encoder cl\u00e1sico `Flatten -> Linear(16\u219232) -> ReLU -> Linear(32\u21924)`; \u00e1ngulos $\\alpha = \\arcsin(\\sigma(h)) \\in \\mathbb{R}^4$ con $\\sigma$ = sigmoid.\n",
    "- PQC: escalera de profundidad $L=2$ con $n_q=4$ qubits y compuertas ZZ (descompuestas en CX-RZ-CX). Estado final $U_{\\text{PQC}}(\\theta)\\, U_{\\text{enc}}(\\alpha)\\, |0\\rangle^{\\otimes n_q}$.\n",
    "- Medici\u00f3n AMM: se miden $\\langle \\sigma_x \\rangle, \\langle \\sigma_y \\rangle, \\langle \\sigma_z \\rangle$ en cada qubit; $m_{\\text{AMM}} \\in \\mathbb{R}^{3 n_q}$ (12 features para 4 qubits).\n",
    "- Clasificador: `LayerNorm -> Linear(12\u219232) -> ReLU -> Linear(32\u219210)`; `CrossEntropyLoss` aplica softmax interno.\n",
    "\n",
    "### Flujo de datos y etiquetado\n",
    "- Etiquetas $y \\in \\{0,\\dots,9\\}$ provienen directamente de MNIST (sin one-hot).\n",
    "- Forward: $z = f_{\\text{class}}(m_{\\text{AMM}})$; pred = argmax$(z)$; $\\mathcal{L} = \\text{CE}(z, y)$. Misma divisi\u00f3n train/val/test que en el resto del notebook.\n",
    "\n",
    "### Diferencias con `red_hibrida.ipynb`\n",
    "- Observables: all\u00ed se mide un solo observable ($\\sum Z$ -> 1 feature); aqu\u00ed AMM en 4 qubits entrega 12 features, m\u00e1s se\u00f1al para el clasificador.\n",
    "- Encoder: all\u00ed CNN completa 28\u00d728 + FC grande; aqu\u00ed reducci\u00f3n 4\u00d74 + encoder peque\u00f1o, bajando c\u00f3mputo y llamadas cu\u00e1nticas.\n",
    "- Gradientes: all\u00ed se propagan gradientes tambi\u00e9n a las entradas del PQC; aqu\u00ed solo a $\\theta$ del PQC (parameter-shift), lo que reduce ejecuciones cu\u00e1nticas en backward.\n",
    "\n",
    "### Optimizaci\u00f3n y parameter-shift\n",
    "- P\u00e9rdida en un minibatch $B$: $\\mathcal{L} = -\\frac{1}{|B|} \\sum_{i \\in B} \\log(\\text{softmax}(z_i)_{y_i})$.\n",
    "- Gradientes cu\u00e1nticos via parameter-shift para cada $\\theta_j$: $\\partial_{\\theta_j}\\mathcal{L} \\approx \\tfrac{1}{2} [\\mathcal{L}(\\theta_j + \\tfrac{\\pi}{2}) - \\mathcal{L}(\\theta_j - \\tfrac{\\pi}{2})]$, aplicados solo a las $\\theta$ del PQC; encoder y clasificador usan backprop est\u00e1ndar.\n",
    "- Actualizaci\u00f3n con Adam (lr = $8\\times10^{-4}$) y scheduler StepLR ($\\gamma=0.2$ cada 7 \u00e9pocas).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918cbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar las librer\u00edas necesarias\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Para asegurar que los resultados sean reproducibles\n",
    "torch.manual_seed(33)\n",
    "\n",
    "cudaq.set_random_seed(33)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582043a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el dispositivo\n",
    "# Set CUDAQ and PyTorch to run on either CPU or GPU.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    cudaq.set_target(\"nvidia\")\n",
    "    print(\"\u2705 Dispositivo configurado para GPU (CUDA).\")\n",
    "else:\n",
    "    cudaq.set_target(\"qpp-cpu\")\n",
    "    print(\"\u26a0\ufe0f GPU no encontrada. Usando CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324333d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b13cbb16",
   "metadata": {},
   "source": [
    "## Descripci\u00f3n del Conjunto de Datos MNIST\n",
    "\n",
    "- *\u00bfQu\u00e9 es?:* MNIST (Modified National Institute of Standards and Technology database) es una gran base de datos de d\u00edgitos escritos a mano, del 0 al 9.\n",
    "- *Contenido:* Contiene 70,000 im\u00e1genes en escala de grises.\n",
    "- *Conjunto de entrenamiento:* 60,000 im\u00e1genes.\n",
    "- *Conjunto de prueba:* 10,000 im\u00e1genes.\n",
    "- *Formato de imagen:* Cada imagen tiene un tama\u00f1o de 28x28 p\u00edxeles.\n",
    "- *Uso com\u00fan:* Es considerado el \"Hola, Mundo\" de la visi\u00f3n por computadora y el aprendizaje profundo. Se utiliza para entrenar y probar algoritmos de clasificaci\u00f3n de im\u00e1genes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeaf4a4",
   "metadata": {},
   "source": [
    "Paso 2: Cargar, Transformar y Previsualizar los Datos\n",
    "torchvision nos facilita la descarga y preparaci\u00f3n de datasets.\n",
    "\n",
    "Transformaciones: Convertimos las im\u00e1genes a tensores de PyTorch y las normalizamos. La normalizaci\u00f3n (ajustar los valores de los p\u00edxeles para que tengan una media de 0.5 y una desviaci\u00f3n est\u00e1ndar de 0.5) ayuda a que el modelo entrene m\u00e1s r\u00e1pido y de forma m\u00e1s estable.\n",
    "Descarga: Descargamos los conjuntos de entrenamiento y prueba. FashionMNIST ya viene separado en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaci\u00f3n 4x4 inspirada en la reducci\u00f3n del paper (Figura 2)\n",
    "# 1) Normaliza a [0,1] con ToTensor\n",
    "# 2) Recorta 4 p\u00edxeles por lado (28 -> 20)\n",
    "# 3) Promedia cada bloque 5x5 para obtener una imagen 4x4\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda t: t[:, 4:-4, 4:-4]),\n",
    "    transforms.Lambda(lambda t: F.avg_pool2d(t, kernel_size=5, stride=5)),\n",
    "])\n",
    "\n",
    "# Descargar los datasets de entrenamiento y prueba con la transformaci\u00f3n reducida\n",
    "train_full_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Tama\u00f1o total del dataset de entrenamiento: {len(train_full_dataset)}\")\n",
    "print(f\"Tama\u00f1o del dataset de prueba: {len(test_dataset)}\")\n",
    "print(f\"Dimensi\u00f3n tras reducci\u00f3n: {train_full_dataset[0][0].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subconjunto configurable (por defecto se usa todo el dataset de entrenamiento reducido)\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_subset_for_testing = Subset(train_full_dataset, range(n_samples_prueba))\n",
    "\n",
    "train_size = int(0.8 * len(train_subset_for_testing))\n",
    "val_size = len(train_subset_for_testing) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_subset_for_testing, [train_size, val_size])\n",
    "\n",
    "print(f\"Tama\u00f1o del subconjunto de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"Tama\u00f1o del subconjunto de validaci\u00f3n: {len(val_dataset)}\")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clases de MNIST (d\u00edgitos del 0 al 9)\n",
    "classes = tuple(str(i) for i in range(10))\n",
    "\n",
    "# Funci\u00f3n para mostrar im\u00e1genes reducidas\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.squeeze(np.transpose(npimg, (1, 2, 0))), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Obtener un lote de im\u00e1genes de entrenamiento\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Mostrar las primeras 8 im\u00e1genes reducidas\n",
    "imshow(torchvision.utils.make_grid(images[:8], nrow=8))\n",
    "print('Etiquetas: ', ' '.join(f'{classes[labels[j]]}' for j in range(8)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb2cf2-d5f8-4fd1-a150-a0715a1a9fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Guardar los pesos del modelo entrenado (con versionado) ---\n",
    "import os\n",
    "\n",
    "def save_model(model, base_name):\n",
    "    \"\"\"\n",
    "    Guarda el modelo. Si ya existe un archivo con el mismo nombre base,\n",
    "    crea una nueva versi\u00f3n (ej. _v2.0.pth, _v3.0.pth, etc.).\n",
    "    \"\"\"\n",
    "    # Construye el nombre del archivo base\n",
    "    file_path = f\"{base_name}.pth\"\n",
    "\n",
    "    # Si el archivo base no existe, lo guarda con ese nombre y termina.\n",
    "    if not os.path.exists(file_path):\n",
    "        torch.save(model.state_dict(), file_path)\n",
    "        print(f\"\u00a1Modelo guardado exitosamente en {file_path}!\")\n",
    "        return\n",
    "\n",
    "    # Si el archivo base ya existe, busca la siguiente versi\u00f3n disponible.\n",
    "    version = 2\n",
    "    while True:\n",
    "        # Creamos el nombre de archivo versionado (ej: hybrid_cnn_mnist_weights_v2.0.pth)\n",
    "        # Usamos un guion bajo en lugar de \":\" para compatibilidad con el sistema de archivos.\n",
    "        versioned_path = f\"{base_name}_v{version:.1f}.pth\"\n",
    "        \n",
    "        # Si no existe un archivo con ese nombre de versi\u00f3n, lo guardamos y salimos del bucle.\n",
    "        if not os.path.exists(versioned_path):\n",
    "            torch.save(model.state_dict(), versioned_path)\n",
    "            print(f\"\u00a1Modelo guardado exitosamente en {versioned_path}!\")\n",
    "            break\n",
    "        \n",
    "        # Si ya existe, incrementamos la versi\u00f3n y volvemos a intentarlo.\n",
    "        version += 1\n",
    "\n",
    "# Ejemplo de c\u00f3mo se llamar\u00eda (no es necesario que cambies esto en la celda de entrenamiento):\n",
    "# save_model(model, \"cnn_mnist_weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hyperparameters-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hiperpar\u00e1metros del Modelo y Entrenamiento ---\n",
    "# Versi\u00f3n ligera: 4 qubits + medici\u00f3n AMM (12 features) + PQC en escalera poco profunda\n",
    "n_qubits = 4\n",
    "pqc_layers = 2  # profundidad baja para reducir llamadas cu\u00e1nticas\n",
    "n_samples_prueba = 12000  # subconjunto para experimentar r\u00e1pido; pon 60000 para todo MNIST reducido\n",
    "batch_size = 64\n",
    "epochs = 15\n",
    "learning_rate = 8e-4  # LR moderado para estabilidad con el bloque cu\u00e1ntico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd9cb5-5e94-40f2-9ede-5a9ce6e0bc0c",
   "metadata": {},
   "source": [
    "## Implementaci\u00f3n del Modelo H\u00edbrido Cu\u00e1ntico-Cl\u00e1sico\n",
    "\n",
    "Ahora, construiremos y entrenaremos el modelo h\u00edbrido. Este modelo combinar\u00e1 capas convolucionales cl\u00e1sicas para la extracci\u00f3n de caracter\u00edsticas con un circuito cu\u00e1ntico parametrizado para el procesamiento de la informaci\u00f3n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c47104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "from cudaq import spin\n",
    "\n",
    "# Circuito AMM con pocos qubits y medici\u00f3n X/Y/Z en todos los qubits\n",
    "ladder_depth = pqc_layers\n",
    "theta_kernel, data_params, theta_params = cudaq.make_kernel(list, list)\n",
    "qubits = theta_kernel.qalloc(n_qubits)\n",
    "\n",
    "# Codificaci\u00f3n por \u00e1ngulos RY\n",
    "for i in range(n_qubits):\n",
    "    theta_kernel.ry(data_params[i], qubits[i])\n",
    "\n",
    "# PQC en escalera con compuertas ZZ descompuestas en CX-RZ-CX\n",
    "theta_index = 0\n",
    "for _ in range(ladder_depth):\n",
    "    for j in range(n_qubits - 1):\n",
    "        theta_kernel.cx(qubits[j], qubits[j + 1])\n",
    "        theta_kernel.rz(2 * theta_params[theta_index], qubits[j + 1])\n",
    "        theta_kernel.cx(qubits[j], qubits[j + 1])\n",
    "        theta_index += 1\n",
    "\n",
    "# Medici\u00f3n X/Y/Z en todos los qubits -> 3 * n_qubits salidas\n",
    "measurement_ops = []\n",
    "for op in (spin.x, spin.y, spin.z):\n",
    "    for q in range(n_qubits):\n",
    "        measurement_ops.append(op(q))\n",
    "\n",
    "\n",
    "def evaluate_expectations(sample_angles, theta_values):\n",
    "    \"\"\"Ejecuta el kernel y devuelve <X|Y|Z> de cada qubit.\"\"\"\n",
    "    obs_results = []\n",
    "    for obs in measurement_ops:\n",
    "        res = cudaq.observe(theta_kernel, obs, sample_angles, theta_values)\n",
    "        obs_results.append(res.expectation())\n",
    "    return obs_results\n",
    "\n",
    "\n",
    "def evaluate_batch(data_tensor, theta_values, device):\n",
    "    \"\"\"Eval\u00faa un batch completo para usar en forward y backward.\"\"\"\n",
    "    batch_results = []\n",
    "    for row in data_tensor:\n",
    "        batch_results.append(evaluate_expectations(row.detach().cpu().tolist(), theta_values))\n",
    "    return torch.tensor(batch_results, device=device, dtype=data_tensor.dtype)\n",
    "\n",
    "\n",
    "class QuantumFunction(Function):\n",
    "    \"\"\"Autograd manual: gradiente solo sobre par\u00e1metros cu\u00e1nticos para ahorrar c\u00f3mputo.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, data: torch.Tensor, thetas: torch.Tensor):\n",
    "        ctx.save_for_backward(data, thetas)\n",
    "        theta_list = thetas.detach().cpu().tolist()\n",
    "        return evaluate_batch(data, theta_list, data.device)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: torch.Tensor):\n",
    "        data, thetas = ctx.saved_tensors\n",
    "        theta_list = thetas.detach().cpu().tolist()\n",
    "        shift = np.pi / 2.0\n",
    "\n",
    "        gradients_theta = torch.zeros_like(thetas)\n",
    "        # Solo calculamos gradientes respecto a theta (la entrada no requiere gradiente)\n",
    "        for t_idx in range(len(theta_list)):\n",
    "            theta_plus = theta_list.copy()\n",
    "            theta_minus = theta_list.copy()\n",
    "            theta_plus[t_idx] += shift\n",
    "            theta_minus[t_idx] -= shift\n",
    "\n",
    "            exp_plus = evaluate_batch(data, theta_plus, data.device)\n",
    "            exp_minus = evaluate_batch(data, theta_minus, data.device)\n",
    "            gradient_component = 0.5 * (exp_plus - exp_minus)\n",
    "            gradients_theta[t_idx] = (gradient_component * grad_output).sum()\n",
    "\n",
    "        return None, gradients_theta\n",
    "\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    \"\"\"Capa cu\u00e1ntica con par\u00e1metros entrenables del PQC (profundidad en escalera).\"\"\"\n",
    "    def __init__(self, n_qubits: int, ladder_depth: int):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.ladder_depth = ladder_depth\n",
    "        self.theta = nn.Parameter(torch.zeros((n_qubits - 1) * ladder_depth))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return QuantumFunction.apply(x, self.theta)\n",
    "\n",
    "\n",
    "class HybridAMM(nn.Module):\n",
    "    \"\"\"Modelo h\u00edbrido ligero: encoder cl\u00e1sico peque\u00f1o + PQC AMM + clasificador.\"\"\"\n",
    "    def __init__(self, n_qubits: int = n_qubits, ladder_depth: int = pqc_layers):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "\n",
    "        # Encoder cl\u00e1sico compacto para comprimir 4x4=16 features a 4 \u00e1ngulos\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, n_qubits),\n",
    "        )\n",
    "\n",
    "        self.quantum = QuantumLayer(n_qubits, ladder_depth)\n",
    "\n",
    "        # 3 observables por qubit -> 12 features para 4 qubits\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(3 * n_qubits),\n",
    "            nn.Linear(3 * n_qubits, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Normaliza a [0,1] y usa arcsin como en el paper\n",
    "        angles = torch.sigmoid(self.encoder(x))\n",
    "        angles = torch.arcsin(torch.clamp(angles, 0.0, 1.0))\n",
    "\n",
    "        q_out = self.quantum(angles)\n",
    "        logits = self.classifier(q_out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba130a2-392d-4f50-bb18-852413f7bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Creaci\u00f3n y Validaci\u00f3n del Modelo ---\n",
    "\n",
    "# Crear instancia del modelo h\u00edbrido ligero con AMM\n",
    "hybrid_model = HybridAMM(n_qubits=n_qubits, ladder_depth=pqc_layers).to(device)\n",
    "print(\"--- Arquitectura del Modelo H\u00edbrido (AMM ligero) ---\")\n",
    "print(hybrid_model)\n",
    "\n",
    "# --- Test de Validaci\u00f3n Cu\u00e1ntico-Cl\u00e1sico (Forward y Backward) ---\n",
    "print(\"--- Realizando Test de Validaci\u00f3n Cu\u00e1ntico-Cl\u00e1sico ---\")\n",
    "\n",
    "test_input = torch.randn(4, 1, 4, 4).to(device)  # im\u00e1genes ya reducidas a 4x4\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "\n",
    "output = hybrid_model(test_input)\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(\"\u2705 Pase hacia adelante completado\")\n",
    "\n",
    "# Pase hacia atr\u00e1s\n",
    "target = torch.randint(0, 10, (4,)).to(device)\n",
    "loss_fn_test = nn.CrossEntropyLoss()\n",
    "loss = loss_fn_test(output, target)\n",
    "loss.backward()\n",
    "\n",
    "grad_pre_quantum = list(hybrid_model.quantum.parameters())[0].grad\n",
    "if grad_pre_quantum is not None and grad_pre_quantum.abs().sum() > 0:\n",
    "    print(\"\u2705 Backward funcionando: gradientes fluyen hasta el PQC y el clasificador.\")\n",
    "else:\n",
    "    print(\"\u274c Error en el backward: sin gradientes en el PQC.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-train-markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo H\u00edbrido\n",
    "\n",
    "Ahora, entrenaremos el modelo h\u00edbrido usando el mismo bucle de entrenamiento que para el modelo cl\u00e1sico. Notar\u00e1s que el entrenamiento puede ser m\u00e1s lento debido a la simulaci\u00f3n de los circuitos cu\u00e1nticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-train-validation-loops",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definir los bucles de entrenamiento y validaci\u00f3n ---\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"Bucle para una \u00e9poca de entrenamiento.\"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() # Poner el modelo en modo de entrenamiento\n",
    "    total_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Mover datos al dispositivo (CPU o GPU)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Calcular la predicci\u00f3n y la p\u00e9rdida\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validation_loop(dataloader, model, loss_fn):\n",
    "    \"\"\"Bucle para evaluar el modelo en el conjunto de validaci\u00f3n o prueba.\"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() # Poner el modelo en modo de evaluaci\u00f3n\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad(): # No necesitamos calcular gradientes aqu\u00ed\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-train-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Entrenamiento del Modelo H\u00edbrido ---\n",
    "import time\n",
    "# Definir la funci\u00f3n de p\u00e9rdida y el optimizador\n",
    "loss_fn_hybrid = nn.CrossEntropyLoss()\n",
    "optimizer_hybrid = optim.Adam(hybrid_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Reducimos el learning rate en un factor de 0.2 cada 7 \u00e9pocas\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer_hybrid, step_size=7, gamma=0.2)\n",
    "# Listas para almacenar el historial de entrenamiento\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
    "\n",
    "# Bucle principal de entrenamiento para el modelo h\u00edbrido\n",
    "print(\"\n",
    "--- Iniciando Entrenamiento del Modelo H\u00edbrido AMM con MNIST ---\")\n",
    "start_time = time.time()\n",
    "for t in range(epochs):\n",
    "    print(f\"\u00c9poca {t+1}\n",
    "-------------------------------\")\n",
    "    print(\"Entrenando (H\u00edbrido AMM)...\")\n",
    "    train_loss = train_loop(train_loader, hybrid_model, loss_fn_hybrid, optimizer_hybrid)\n",
    "    print(\"Validando (H\u00edbrido AMM)...\")\n",
    "    val_loss, val_acc = validation_loop(val_loader, hybrid_model, loss_fn_hybrid)\n",
    "    \n",
    "    # Guardar m\u00e9tricas de la \u00e9poca\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "    scheduler.step()\n",
    "\n",
    "end_time = time.time()\n",
    "total_training_time = end_time - start_time\n",
    "print(\"\u00a1Entrenamiento h\u00edbrido finalizado!\")\n",
    "\n",
    "# Evaluar el modelo h\u00edbrido en el conjunto de prueba\n",
    "print(\"\n",
    "--- Evaluando Modelo H\u00edbrido AMM con el conjunto de Prueba (Test) ---\")\n",
    "validation_loop(test_loader, hybrid_model, loss_fn_hybrid)\n",
    "\n",
    "# Guardar los pesos del modelo h\u00edbrido entrenado\n",
    "save_model(hybrid_model, \"hybrid_amm_mnist_weights_gpu\" if device==\"cuda\" else \"hybrid_amm_mnist_weights_cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualizaci\u00f3n de Resultados ---\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Usamos las variables definidas en las celdas anteriores\n",
    "num_epochs = epochs\n",
    "num_train_samples = len(train_dataset)\n",
    "\n",
    "# Determinar el nombre del dispositivo para el t\u00edtulo de la gr\u00e1fica\n",
    "if device == \"cuda\":\n",
    "    device_name = f\"GPU ({torch.cuda.get_device_name(0)})\"\n",
    "else:\n",
    "    device_name = \"CPU\"\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# T\u00edtulo principal de la figura con la nueva informaci\u00f3n del dispositivo\n",
    "title_text = \"\n",
    "\".join([\n",
    "    \"Modelo H\u00edbrido AMM - Historial de Entrenamiento\",\n",
    "    f\"({num_epochs} \u00e9pocas en {num_train_samples} muestras) batch_size={batch_size}\",\n",
    "    f\"Ejecutado en: {device_name}\",\n",
    "    f\"Tiempo total de entrenamiento: {total_training_time:.2f} segundos\",\n",
    "])\n",
    "fig.suptitle(title_text, fontsize=16)\n",
    "\n",
    "# Gr\u00e1fica de P\u00e9rdida (Loss)\n",
    "ax1.plot(history['train_loss'], label='P\u00e9rdida de Entrenamiento', marker='o')\n",
    "ax1.plot(history['val_loss'], label='P\u00e9rdida de Validaci\u00f3n', marker='o')\n",
    "ax1.set_ylabel('P\u00e9rdida (Loss)')\n",
    "ax1.set_title('P\u00e9rdida a lo largo de las \u00c9pocas')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Gr\u00e1fica de Precisi\u00f3n (Accuracy)\n",
    "ax2.plot(history['val_accuracy'], label='Precisi\u00f3n de Validaci\u00f3n', color='green', marker='o')\n",
    "ax2.set_xlabel('\u00c9pocas')\n",
    "ax2.set_ylabel('Precisi\u00f3n (Accuracy)')\n",
    "ax2.set_title('Precisi\u00f3n de Validaci\u00f3n a lo largo de las \u00c9pocas')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-random-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "hybrid_model.eval()\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "idx = random.randint(0, len(images) - 1)\n",
    "img = images[idx].unsqueeze(0)\n",
    "true_label = labels[idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = hybrid_model(img)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "img_display = img.cpu().squeeze()\n",
    "plt.imshow(img_display, cmap='gray')\n",
    "plt.title(f\"Etiqueta Real: {classes[true_label]} | Predicci\u00f3n: {classes[predicted.item()]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4e51f-bc3c-4bdf-bfa7-303685cb3d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132a6f4-2866-4e21-b4fb-6b0c0bced3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_braket",
   "language": "python",
   "name": "conda_braket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}